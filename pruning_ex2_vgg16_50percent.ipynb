{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning 실험\n",
    "\n",
    "### \"RETHINKING OF THE VALUE OF THE NETWORK PRUNING\" 논문을 implemenatation 한 것. \n",
    "\n",
    "본 과정은 ChatGPT 와 함께 진행하였으며 Pruning 에 대한 전반적인 이해도를 높이고 실제 경량화와 성능 차이를 확인하기 위해서 진행하였습니다. \n",
    "\n",
    "Baseline model : VGG-16 \n",
    "\n",
    "Training dataset : CIFAR100 \n",
    "\n",
    "Pruning setup : 50%\n",
    "\n",
    "Pruning strategy : filter pruning vs Unstructure Pruning \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 : Dataset 로드 & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR100 데이터를 위한 Preprocess\n",
    "# 여러 이미지 transformation을 하나의 pipeline으로 통합 \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(), #Image 를 pytorch tensor 형태로 변형 \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:19<00:00, 8664082.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Training set size: 50000 samples\n",
      "Test set size: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# # CIFAR-100 Dataset 로드 \n",
    "\n",
    "# Automatically download CIFAR-100 and load it into the training and test datasets\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)  # Automatically download and load training data\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)  # Automatically download and load test data\n",
    "\n",
    "# Create DataLoaders for the CIFAR-100 train and test datasets\n",
    "# DataLoader는 모델이 여러 샘플을 동시에 처리할 수 있게 함. \n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8)\n",
    "\n",
    "# Check dataset sizes to ensure they are loaded correctly\n",
    "print(f\"Training set size: {len(train_dataset)} samples\")\n",
    "print(f\"Test set size: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: ResNet 모델 초기화 (ImageNEt으로 사전 훈련된 가중치를 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning 사용. \n",
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STep4 : ResNet-50 모델의 마지막 Layer, FC layer을 CIFAR100에 맞춰 조정 \n",
    "\n",
    "이는 기존의 ImageNet을 위한 ResNet-50 모델은 1000개 클래스를 분류하는 모델이므로 조정해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : model 을 GPU에 옮기기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 손실함수와 최적화 함수 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # 다중 분류를 위한 크로스 엔트로피 손실함수 \n",
    "# label_smoothing 을 사용하여 \n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr = 0.01,\n",
    "                      momentum= 0.9,\n",
    "                      weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label smoothing 이란 ? \n",
    "    분류 모델 학습 시 사용되는 정규화 기법. 과확신을 방지하기 위해 사용 .\n",
    "    one-hot encoding 시 정답을 1, 그 외를 0으로 설정하지만 smoothing 을 통해 soft label을 만듦. \n",
    "    [1, 0, 0, 0, .... 0] => [0.9, 0.001, 0.001 ... 0.001]\n",
    "\n",
    "    (출처 : https://maxima-lab.tistory.com/entry/Deep-Learning-Label-Smoothing-Tensorflow )     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Validation loss를 계산하기 위한 validation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU if available\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    return val_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : 훈련 Loop 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "#Early Stopping 설정\n",
    "early_stopping_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs = 50):\n",
    "    global best_val_loss, epochs_no_improve\n",
    "\n",
    "    for epoch in range (num_epochs):\n",
    "        running_loss = 0.0 #훈련 중 loss 를 추적 \n",
    "        model.train() #훈련 모델 설정   \n",
    "\n",
    "        #tqdm 을 활용하여 각 epoch 마다 progress bar 표시 \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) #Data를 GPU로 옮기기 \n",
    "            optimizer.zero_grad() #각 batch 에서 나온 grad를 초기화. \n",
    "            outputs = model(inputs) # Forward Pass\n",
    "            loss = criterion(outputs, labels) #loss를 계산 \n",
    "            loss.backward() #backpropagation, gradient 계산\n",
    "            optimizer.step() #모델의 가중치 업데이트\n",
    "            running_loss += loss.item() # loss를 누적 \n",
    "\n",
    "            # progress bar 표시\n",
    "            progress_bar.set_postfix(loss = running_loss / len(train_loader))\n",
    "        \n",
    "        val_loss = validate_model(model, test_loader, criterion)\n",
    "        print(f\"Epoch [{epoch+1} / {num_epochs}], Loss : {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        #validation loss가 개선되었는지 확인\n",
    "        if val_loss < best_val_loss :\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else :\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        \n",
    "        # Early stopping check\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traine_model 이 local 에 있을 시, load\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : 모델을 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found! Loading the model from disk...\n",
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74837/3070116513.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = \"vgg_trained_model.pth\"\n",
    "\n",
    "# Check if the model exists in the local directory\n",
    "if os.path.exists(model_path):\n",
    "    # If model exists, load the saved model\n",
    "    print(\"Model found! Loading the model from disk...\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    trained_model = model.to(device)  # Move to GPU if available\n",
    "    print(\"Model loaded successfully!\")\n",
    "else:\n",
    "    # If model doesn't exist, proceed with training\n",
    "    print(\"No saved model found. Training a new model...\")\n",
    "    trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# After training or at intermediate checkpoints\u001b[39;00m\n\u001b[1;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg_trained_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mtrained_model\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), save_path)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : 모델 평가 \n",
    "accuracy 뿐만 아니라 f1 score, precision, recall, inference_time 도 함께 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Evaluation:\n",
      "Accuracy: 76.51%\n",
      "Precision: 0.7710, Recall: 0.7651, F1-Score: 0.7653\n",
      "Inference Time: 19.8682 seconds\n",
      "Model Size: 538.69 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    start_time = time.time()  # Start timer for inference time\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Accuracy calculation\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Precision, Recall, F1-score\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Inference time\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    return accuracy, precision, recall, f1, inference_time\n",
    "\n",
    "# Function to calculate model size\n",
    "def calculate_model_size(model):\n",
    "    torch.save(model.state_dict(), \"temp_model.pth\")\n",
    "    model_size = os.path.getsize(\"temp_model.pth\") / 1e6  # Convert to MB\n",
    "    os.remove(\"temp_model.pth\")\n",
    "    return model_size\n",
    "\n",
    "# Step 2: Evaluate the original trained ResNet-50 model\n",
    "print(\"Original Model Evaluation:\")\n",
    "accuracy, precision, recall, f1, inference_time = evaluate_model(trained_model, test_loader)\n",
    "model_size = calculate_model_size(trained_model)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "print(f\"Model Size: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11 : Pruning \n",
    "1. Unstructured Pruning (50%) no Fine-tuning vs with fine-tuning\n",
    "2. Structured Pruning (50% filter) no FIne-tuning vs with fine-tuning\n",
    "3. Unstructured Pruning (50%) with scratch\n",
    "4. Strcuctured Pruning with scratch \n",
    "\n",
    "위와 같은 6개의 pruning 모델 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured Pruning (individual weight를 가지치기)\n",
    "def apply_unstructured_pruning(model, amount=0.5):\n",
    "    # Conv2d 와 Linear layer에 pruning 적용\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            print(f'Applied unstructured pruning to {name}, amount={amount}')\n",
    "    return model\n",
    "\n",
    "# Structured Pruing (filter pruning)\n",
    "def apply_structured_pruning(model, amount=0.5):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.ln_structured(module, name='weight', amount=amount, n=1, dim=0)  # dim=0 means prune filters\n",
    "            print(f'Applied structured pruning to {name}, amount={amount}')\n",
    "    return model\n",
    "\n",
    "#Fine-tuning 함수\n",
    "def fine_tune_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=3):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(train_loader))\n",
    "        val_loss = validate_model(model, test_loader, criterion)\n",
    "        print(f'Epoch {epoch+1}, Fine-tuned Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "# Pruned model 의 가중치를 재 초기화하는 함수 \n",
    "def reinitialize_weights(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "    return model\n",
    "\n",
    "# Function to train from scratch\n",
    "def train_scratch(model, train_loader, test_loader, criterion, optimizer, num_epochs=22):\n",
    "    return fine_tune_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clear cache after certain operations or between batches\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12 : 가지치기 모델 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied unstructured pruning to features.0, amount=0.5\n",
      "Applied unstructured pruning to features.2, amount=0.5\n",
      "Applied unstructured pruning to features.5, amount=0.5\n",
      "Applied unstructured pruning to features.7, amount=0.5\n",
      "Applied unstructured pruning to features.10, amount=0.5\n",
      "Applied unstructured pruning to features.12, amount=0.5\n",
      "Applied unstructured pruning to features.14, amount=0.5\n",
      "Applied unstructured pruning to features.17, amount=0.5\n",
      "Applied unstructured pruning to features.19, amount=0.5\n",
      "Applied unstructured pruning to features.21, amount=0.5\n",
      "Applied unstructured pruning to features.24, amount=0.5\n",
      "Applied unstructured pruning to features.26, amount=0.5\n",
      "Applied unstructured pruning to features.28, amount=0.5\n",
      "Applied unstructured pruning to classifier.0, amount=0.5\n",
      "Applied unstructured pruning to classifier.3, amount=0.5\n",
      "Applied unstructured pruning to classifier.6, amount=0.5\n",
      "Applied structured pruning to features.0, amount=0.5\n",
      "Applied structured pruning to features.2, amount=0.5\n",
      "Applied structured pruning to features.5, amount=0.5\n",
      "Applied structured pruning to features.7, amount=0.5\n",
      "Applied structured pruning to features.10, amount=0.5\n",
      "Applied structured pruning to features.12, amount=0.5\n",
      "Applied structured pruning to features.14, amount=0.5\n",
      "Applied structured pruning to features.17, amount=0.5\n",
      "Applied structured pruning to features.19, amount=0.5\n",
      "Applied structured pruning to features.21, amount=0.5\n",
      "Applied structured pruning to features.24, amount=0.5\n",
      "Applied structured pruning to features.26, amount=0.5\n",
      "Applied structured pruning to features.28, amount=0.5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Step 1: Model 1 - Unstructured Pruning (50%) without Fine-Tuning\n",
    "model_unstructured = copy.deepcopy(trained_model)\n",
    "model_unstructured = apply_unstructured_pruning(model_unstructured, amount=0.5)\n",
    "\n",
    "# Step 2: Model 2 - Structured Pruning (50% Filter Pruning) without Fine-Tuning\n",
    "model_structured = copy.deepcopy(trained_model)\n",
    "model_structured = apply_structured_pruning(model_structured, amount=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied unstructured pruning to features.0, amount=0.5\n",
      "Applied unstructured pruning to features.2, amount=0.5\n",
      "Applied unstructured pruning to features.5, amount=0.5\n",
      "Applied unstructured pruning to features.7, amount=0.5\n",
      "Applied unstructured pruning to features.10, amount=0.5\n",
      "Applied unstructured pruning to features.12, amount=0.5\n",
      "Applied unstructured pruning to features.14, amount=0.5\n",
      "Applied unstructured pruning to features.17, amount=0.5\n",
      "Applied unstructured pruning to features.19, amount=0.5\n",
      "Applied unstructured pruning to features.21, amount=0.5\n",
      "Applied unstructured pruning to features.24, amount=0.5\n",
      "Applied unstructured pruning to features.26, amount=0.5\n",
      "Applied unstructured pruning to features.28, amount=0.5\n",
      "Applied unstructured pruning to classifier.0, amount=0.5\n",
      "Applied unstructured pruning to classifier.3, amount=0.5\n",
      "Applied unstructured pruning to classifier.6, amount=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 3125/3125 [05:10<00:00, 10.08it/s, loss=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 0.8957, Validation Loss: 1.7626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 3125/3125 [05:12<00:00,  9.99it/s, loss=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 0.8460, Validation Loss: 1.7626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 3125/3125 [05:11<00:00, 10.03it/s, loss=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 0.8460, Validation Loss: 1.7626\n",
      "Applied structured pruning to features.0, amount=0.5\n",
      "Applied structured pruning to features.2, amount=0.5\n",
      "Applied structured pruning to features.5, amount=0.5\n",
      "Applied structured pruning to features.7, amount=0.5\n",
      "Applied structured pruning to features.10, amount=0.5\n",
      "Applied structured pruning to features.12, amount=0.5\n",
      "Applied structured pruning to features.14, amount=0.5\n",
      "Applied structured pruning to features.17, amount=0.5\n",
      "Applied structured pruning to features.19, amount=0.5\n",
      "Applied structured pruning to features.21, amount=0.5\n",
      "Applied structured pruning to features.24, amount=0.5\n",
      "Applied structured pruning to features.26, amount=0.5\n",
      "Applied structured pruning to features.28, amount=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 3125/3125 [04:53<00:00, 10.66it/s, loss=6.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 6.4229, Validation Loss: 6.2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 3125/3125 [04:52<00:00, 10.68it/s, loss=6.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 6.2617, Validation Loss: 6.2614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 3125/3125 [04:52<00:00, 10.68it/s, loss=6.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 6.2617, Validation Loss: 6.2614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Model 3 - Unstructured Pruning (50%) with Fine-Tuning\n",
    "model_unstructured_finetuned = copy.deepcopy(trained_model)\n",
    "model_unstructured_finetuned = apply_unstructured_pruning(model_unstructured_finetuned, amount=0.5)\n",
    "fine_tuned_unstructured = fine_tune_model(model_unstructured_finetuned, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "# Step 4: Model 4 - Structured Pruning (50%) with Fine-Tuning\n",
    "model_structured_finetuned = copy.deepcopy(trained_model)\n",
    "model_structured_finetuned = apply_structured_pruning(model_structured_finetuned, amount=0.5)\n",
    "fine_tuned_structured = fine_tune_model(model_structured_finetuned, train_loader, test_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied unstructured pruning to features.0, amount=0.5\n",
      "Applied unstructured pruning to features.2, amount=0.5\n",
      "Applied unstructured pruning to features.5, amount=0.5\n",
      "Applied unstructured pruning to features.7, amount=0.5\n",
      "Applied unstructured pruning to features.10, amount=0.5\n",
      "Applied unstructured pruning to features.12, amount=0.5\n",
      "Applied unstructured pruning to features.14, amount=0.5\n",
      "Applied unstructured pruning to features.17, amount=0.5\n",
      "Applied unstructured pruning to features.19, amount=0.5\n",
      "Applied unstructured pruning to features.21, amount=0.5\n",
      "Applied unstructured pruning to features.24, amount=0.5\n",
      "Applied unstructured pruning to features.26, amount=0.5\n",
      "Applied unstructured pruning to features.28, amount=0.5\n",
      "Applied unstructured pruning to classifier.0, amount=0.5\n",
      "Applied unstructured pruning to classifier.3, amount=0.5\n",
      "Applied unstructured pruning to classifier.6, amount=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/22: 100%|██████████| 3125/3125 [05:09<00:00, 10.09it/s, loss=4.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 4.1763, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.11it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.12it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.13it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/22: 100%|██████████| 3125/3125 [05:09<00:00, 10.11it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/22: 100%|██████████| 3125/3125 [05:10<00:00, 10.07it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/22: 100%|██████████| 3125/3125 [05:07<00:00, 10.16it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.13it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/22: 100%|██████████| 3125/3125 [05:07<00:00, 10.18it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/22: 100%|██████████| 3125/3125 [05:09<00:00, 10.10it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/22: 100%|██████████| 3125/3125 [05:10<00:00, 10.07it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.14it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.12it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/22: 100%|██████████| 3125/3125 [05:10<00:00, 10.07it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/22: 100%|██████████| 3125/3125 [05:07<00:00, 10.15it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/22: 100%|██████████| 3125/3125 [05:07<00:00, 10.15it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/22: 100%|██████████| 3125/3125 [05:06<00:00, 10.20it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/22: 100%|██████████| 3125/3125 [05:07<00:00, 10.15it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.13it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/22: 100%|██████████| 3125/3125 [05:11<00:00, 10.03it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/22: 100%|██████████| 3125/3125 [05:09<00:00, 10.11it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/22: 100%|██████████| 3125/3125 [05:08<00:00, 10.12it/s, loss=4.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Fine-tuned Training Loss: 4.1898, Validation Loss: 4.3083\n",
      "Applied structured pruning to features.0, amount=0.5\n",
      "Applied structured pruning to features.2, amount=0.5\n",
      "Applied structured pruning to features.5, amount=0.5\n",
      "Applied structured pruning to features.7, amount=0.5\n",
      "Applied structured pruning to features.10, amount=0.5\n",
      "Applied structured pruning to features.12, amount=0.5\n",
      "Applied structured pruning to features.14, amount=0.5\n",
      "Applied structured pruning to features.17, amount=0.5\n",
      "Applied structured pruning to features.19, amount=0.5\n",
      "Applied structured pruning to features.21, amount=0.5\n",
      "Applied structured pruning to features.24, amount=0.5\n",
      "Applied structured pruning to features.26, amount=0.5\n",
      "Applied structured pruning to features.28, amount=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/22: 100%|██████████| 3125/3125 [04:54<00:00, 10.62it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 4.6053, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.67it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/22: 100%|██████████| 3125/3125 [04:53<00:00, 10.65it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.70it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.69it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/22: 100%|██████████| 3125/3125 [04:51<00:00, 10.73it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.68it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/22: 100%|██████████| 3125/3125 [04:51<00:00, 10.71it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/22: 100%|██████████| 3125/3125 [04:51<00:00, 10.70it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/22: 100%|██████████| 3125/3125 [04:55<00:00, 10.59it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.70it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.67it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/22: 100%|██████████| 3125/3125 [04:51<00:00, 10.72it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/22: 100%|██████████| 3125/3125 [04:53<00:00, 10.66it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.69it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/22: 100%|██████████| 3125/3125 [04:51<00:00, 10.72it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/22: 100%|██████████| 3125/3125 [04:51<00:00, 10.73it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/22: 100%|██████████| 3125/3125 [04:53<00:00, 10.64it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/22: 100%|██████████| 3125/3125 [04:50<00:00, 10.74it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.69it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/22: 100%|██████████| 3125/3125 [04:53<00:00, 10.64it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/22: 100%|██████████| 3125/3125 [04:52<00:00, 10.69it/s, loss=4.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Fine-tuned Training Loss: 4.6052, Validation Loss: 4.6052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Model 5 - Unstructured Pruning (50%) + Scratch (Train from Scratch)\n",
    "model_unstructured_scratch = copy.deepcopy(trained_model)\n",
    "model_unstructured_scratch = apply_unstructured_pruning(model_unstructured_scratch, amount=0.5)\n",
    "model_unstructured_scratch = reinitialize_weights(model_unstructured_scratch)\n",
    "scratch_unstructured = train_scratch(model_unstructured_scratch, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "# Step 6: Model 6 - Structured Pruning (50%) + Scratch (Train from Scratch)\n",
    "model_structured_scratch = copy.deepcopy(trained_model)\n",
    "model_structured_scratch = apply_structured_pruning(model_structured_scratch, amount=0.5)\n",
    "model_structured_scratch = reinitialize_weights(model_structured_scratch)\n",
    "scratch_structured = train_scratch(model_structured_scratch, train_loader, test_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13 : Pruned 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 메서드 생성 \n",
    "def evaluate_and_print_results(models, model_names, test_loader):\n",
    "    for model, name in zip(models, model_names):\n",
    "        print(f\"\\n{name}:\")\n",
    "        accuracy, precision, recall, f1, inference_time = evaluate_model(model, test_loader)\n",
    "        model_size = calculate_model_size(model)\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "        print(f\"Inference Time: {inference_time:.4f} seconds, Model Size: {model_size:.2f} MB\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unstructured Pruning (50%):\n",
      "Accuracy: 74.52%\n",
      "Precision: 0.7598, Recall: 0.7452, F1-Score: 0.7471\n",
      "Inference Time: 21.7033 seconds, Model Size: 1077.33 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "Structured Pruning (50%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00%\n",
      "Precision: 0.0001, Recall: 0.0100, F1-Score: 0.0002\n",
      "Inference Time: 20.2045 seconds, Model Size: 597.54 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "Unstructured Pruning + Fine-Tuning (50%):\n",
      "Accuracy: 74.52%\n",
      "Precision: 0.7598, Recall: 0.7452, F1-Score: 0.7471\n",
      "Inference Time: 21.4153 seconds, Model Size: 1077.33 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "Structured Pruning + Fine-Tuning (50%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00%\n",
      "Precision: 0.0001, Recall: 0.0100, F1-Score: 0.0002\n",
      "Inference Time: 20.4356 seconds, Model Size: 597.54 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "Unstructured Pruning + Scratch (50%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.58%\n",
      "Precision: 0.6352, Recall: 0.4758, F1-Score: 0.4693\n",
      "Inference Time: 21.5834 seconds, Model Size: 1077.33 MB\n",
      "--------------------------------------------------\n",
      "\n",
      "Structured Pruning + Scratch (50%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95%\n",
      "Precision: 0.0020, Recall: 0.0095, F1-Score: 0.0024\n",
      "Inference Time: 19.9761 seconds, Model Size: 597.54 MB\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6가지 모델 비교\n",
    "models_to_compare = [\n",
    "    model_unstructured, model_structured, fine_tuned_unstructured, \n",
    "    fine_tuned_structured, scratch_unstructured, scratch_structured\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"Unstructured Pruning (50%)\", \"Structured Pruning (50%)\", \n",
    "    \"Unstructured Pruning + Fine-Tuning (50%)\", \"Structured Pruning + Fine-Tuning (50%)\", \n",
    "    \"Unstructured Pruning + Scratch (50%)\", \"Structured Pruning + Scratch (50%)\"\n",
    "]\n",
    "\n",
    "evaluate_and_print_results(models_to_compare, model_names, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14 : FLOPs 계산, global, layer-wise spasity 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchprofile\n",
    "\n",
    "#FLOPs 계산 메서드 \n",
    "def compute_flops(model, input_size=(1, 3, 224, 224)):\n",
    "    device = next(model.parameters()).device  # Get the current device of the model\n",
    "    model = model.to('cpu')  # Move model to CPU for profiling\n",
    "    flops = torchprofile.profile_macs(model, torch.randn(input_size))\n",
    "    model = model.to(device)  # Move model back to the original device after profiling\n",
    "    return flops\n",
    "\n",
    "\n",
    "# sparsity 계산 메서드 \n",
    "def analyze_sparsity(model):\n",
    "    total_params = 0\n",
    "    total_zero_params = 0\n",
    "    sparsity_info = []\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Get the total number of parameters in the layer\n",
    "            num_params = module.weight.numel()\n",
    "            total_params += num_params\n",
    "            \n",
    "            # Count the number of zero-valued parameters\n",
    "            num_zero_params = torch.sum(module.weight == 0).item()\n",
    "            total_zero_params += num_zero_params\n",
    "            \n",
    "            # Layer-wise sparsity\n",
    "            layer_sparsity = 100 * num_zero_params / num_params\n",
    "            sparsity_info.append((name, layer_sparsity, num_zero_params, num_params))\n",
    "    \n",
    "    # Global sparsity\n",
    "    global_sparsity = 100 * total_zero_params / total_params\n",
    "    return global_sparsity, sparsity_info\n",
    "\n",
    "\n",
    "#print 함수 쉽게 쓰기 위한 메서드 \n",
    "def print_analysis(model_name, flops, global_sparsity, sparsity_details):\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")\n",
    "    print(f\"Global Sparsity: {global_sparsity:.2f}%\")\n",
    "    print(\"Layer-wise Sparsity:\")\n",
    "    for layer, sparsity, zeros, total in sparsity_details:\n",
    "        print(f\"  {layer}: {sparsity:.2f}% sparsity ({zeros}/{total} pruned)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Original Model Analysis ===\n",
      "\n",
      "=== Original Model ===\n",
      "FLOPs: 15.47 GFLOPs\n",
      "Global Sparsity: 0.00%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 0.00% sparsity (0/1728 pruned)\n",
      "  features.2: 0.00% sparsity (0/36864 pruned)\n",
      "  features.5: 0.00% sparsity (0/73728 pruned)\n",
      "  features.7: 0.00% sparsity (0/147456 pruned)\n",
      "  features.10: 0.00% sparsity (0/294912 pruned)\n",
      "  features.12: 0.00% sparsity (0/589824 pruned)\n",
      "  features.14: 0.00% sparsity (0/589824 pruned)\n",
      "  features.17: 0.00% sparsity (0/1179648 pruned)\n",
      "  features.19: 0.00% sparsity (0/2359296 pruned)\n",
      "  features.21: 0.00% sparsity (0/2359296 pruned)\n",
      "  features.24: 0.00% sparsity (0/2359296 pruned)\n",
      "  features.26: 0.00% sparsity (0/2359296 pruned)\n",
      "  features.28: 0.00% sparsity (0/2359296 pruned)\n",
      "  classifier.0: 0.00% sparsity (0/102760448 pruned)\n",
      "  classifier.3: 0.00% sparsity (0/16777216 pruned)\n",
      "  classifier.6: 0.00% sparsity (0/409600 pruned)\n",
      "\n",
      "=== Unstructured Pruned Model (50%) without Fine-Tuning ===\n",
      "FLOPs: 15.60 GFLOPs\n",
      "Global Sparsity: 50.00%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 50.00% sparsity (864/1728 pruned)\n",
      "  features.2: 50.00% sparsity (18432/36864 pruned)\n",
      "  features.5: 50.00% sparsity (36864/73728 pruned)\n",
      "  features.7: 50.00% sparsity (73728/147456 pruned)\n",
      "  features.10: 50.00% sparsity (147456/294912 pruned)\n",
      "  features.12: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.14: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.17: 50.00% sparsity (589824/1179648 pruned)\n",
      "  features.19: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.21: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.24: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.26: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.28: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  classifier.0: 50.00% sparsity (51380224/102760448 pruned)\n",
      "  classifier.3: 50.00% sparsity (8388608/16777216 pruned)\n",
      "  classifier.6: 50.00% sparsity (204800/409600 pruned)\n",
      "\n",
      "=== Structured Pruned Model (50%) without Fine-Tuning ===\n",
      "FLOPs: 15.48 GFLOPs\n",
      "Global Sparsity: 5.46%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 50.00% sparsity (864/1728 pruned)\n",
      "  features.2: 50.00% sparsity (18432/36864 pruned)\n",
      "  features.5: 50.00% sparsity (36864/73728 pruned)\n",
      "  features.7: 50.00% sparsity (73728/147456 pruned)\n",
      "  features.10: 50.00% sparsity (147456/294912 pruned)\n",
      "  features.12: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.14: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.17: 50.00% sparsity (589824/1179648 pruned)\n",
      "  features.19: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.21: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.24: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.26: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.28: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  classifier.0: 0.00% sparsity (0/102760448 pruned)\n",
      "  classifier.3: 0.00% sparsity (0/16777216 pruned)\n",
      "  classifier.6: 0.00% sparsity (0/409600 pruned)\n",
      "\n",
      "=== Unstructured Pruned Model (50%) with Fine-Tuning ===\n",
      "FLOPs: 15.60 GFLOPs\n",
      "Global Sparsity: 50.00%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 50.00% sparsity (864/1728 pruned)\n",
      "  features.2: 50.00% sparsity (18432/36864 pruned)\n",
      "  features.5: 50.00% sparsity (36864/73728 pruned)\n",
      "  features.7: 50.00% sparsity (73728/147456 pruned)\n",
      "  features.10: 50.00% sparsity (147456/294912 pruned)\n",
      "  features.12: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.14: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.17: 50.00% sparsity (589824/1179648 pruned)\n",
      "  features.19: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.21: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.24: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.26: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.28: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  classifier.0: 50.00% sparsity (51380224/102760448 pruned)\n",
      "  classifier.3: 50.00% sparsity (8388608/16777216 pruned)\n",
      "  classifier.6: 50.00% sparsity (204800/409600 pruned)\n",
      "\n",
      "=== Structured Pruned Model (50%) with Fine-Tuning ===\n",
      "FLOPs: 15.48 GFLOPs\n",
      "Global Sparsity: 5.46%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 50.00% sparsity (864/1728 pruned)\n",
      "  features.2: 50.00% sparsity (18432/36864 pruned)\n",
      "  features.5: 50.00% sparsity (36864/73728 pruned)\n",
      "  features.7: 50.00% sparsity (73728/147456 pruned)\n",
      "  features.10: 50.00% sparsity (147456/294912 pruned)\n",
      "  features.12: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.14: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.17: 50.00% sparsity (589824/1179648 pruned)\n",
      "  features.19: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.21: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.24: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.26: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.28: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  classifier.0: 0.00% sparsity (0/102760448 pruned)\n",
      "  classifier.3: 0.00% sparsity (0/16777216 pruned)\n",
      "  classifier.6: 0.00% sparsity (0/409600 pruned)\n",
      "\n",
      "=== Unstructured Pruned Model (50%) + Scratch ===\n",
      "FLOPs: 15.60 GFLOPs\n",
      "Global Sparsity: 50.00%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 50.00% sparsity (864/1728 pruned)\n",
      "  features.2: 50.00% sparsity (18432/36864 pruned)\n",
      "  features.5: 50.00% sparsity (36864/73728 pruned)\n",
      "  features.7: 50.00% sparsity (73728/147456 pruned)\n",
      "  features.10: 50.00% sparsity (147456/294912 pruned)\n",
      "  features.12: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.14: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.17: 50.00% sparsity (589824/1179648 pruned)\n",
      "  features.19: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.21: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.24: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.26: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.28: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  classifier.0: 50.00% sparsity (51380224/102760448 pruned)\n",
      "  classifier.3: 50.00% sparsity (8388608/16777216 pruned)\n",
      "  classifier.6: 50.00% sparsity (204800/409600 pruned)\n",
      "\n",
      "=== Structured Pruned Model (50%) + Scratch ===\n",
      "FLOPs: 15.48 GFLOPs\n",
      "Global Sparsity: 5.46%\n",
      "Layer-wise Sparsity:\n",
      "  features.0: 50.00% sparsity (864/1728 pruned)\n",
      "  features.2: 50.00% sparsity (18432/36864 pruned)\n",
      "  features.5: 50.00% sparsity (36864/73728 pruned)\n",
      "  features.7: 50.00% sparsity (73728/147456 pruned)\n",
      "  features.10: 50.00% sparsity (147456/294912 pruned)\n",
      "  features.12: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.14: 50.00% sparsity (294912/589824 pruned)\n",
      "  features.17: 50.00% sparsity (589824/1179648 pruned)\n",
      "  features.19: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.21: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.24: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.26: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  features.28: 50.00% sparsity (1179648/2359296 pruned)\n",
      "  classifier.0: 0.00% sparsity (5/102760448 pruned)\n",
      "  classifier.3: 0.00% sparsity (2/16777216 pruned)\n",
      "  classifier.6: 0.00% sparsity (0/409600 pruned)\n"
     ]
    }
   ],
   "source": [
    "# Original Model (before pruning)\n",
    "print(\"=== Original Model Analysis ===\")\n",
    "flops_original = compute_flops(trained_model)\n",
    "global_sparsity_original, sparsity_details_original = analyze_sparsity(trained_model)\n",
    "print_analysis(\"Original Model\", flops_original, global_sparsity_original, sparsity_details_original)\n",
    "\n",
    "# Unstructured Pruning Model (without fine-tuning)\n",
    "flops_unstructured = compute_flops(model_unstructured)\n",
    "global_sparsity_unstructured, sparsity_details_unstructured = analyze_sparsity(model_unstructured)\n",
    "print_analysis(\"Unstructured Pruned Model (50%) without Fine-Tuning\", flops_unstructured, global_sparsity_unstructured, sparsity_details_unstructured)\n",
    "\n",
    "# Structured Pruning Model (without fine-tuning)\n",
    "flops_structured = compute_flops(model_structured)\n",
    "global_sparsity_structured, sparsity_details_structured = analyze_sparsity(model_structured)\n",
    "print_analysis(\"Structured Pruned Model (50%) without Fine-Tuning\", flops_structured, global_sparsity_structured, sparsity_details_structured)\n",
    "\n",
    "# Unstructured Pruning Model with Fine-Tuning\n",
    "flops_unstructured_finetuned = compute_flops(fine_tuned_unstructured)\n",
    "global_sparsity_unstructured_finetuned, sparsity_details_unstructured_finetuned = analyze_sparsity(fine_tuned_unstructured)\n",
    "print_analysis(\"Unstructured Pruned Model (50%) with Fine-Tuning\", flops_unstructured_finetuned, global_sparsity_unstructured_finetuned, sparsity_details_unstructured_finetuned)\n",
    "\n",
    "# Structured Pruning Model with Fine-Tuning\n",
    "flops_structured_finetuned = compute_flops(fine_tuned_structured)\n",
    "global_sparsity_structured_finetuned, sparsity_details_structured_finetuned = analyze_sparsity(fine_tuned_structured)\n",
    "print_analysis(\"Structured Pruned Model (50%) with Fine-Tuning\", flops_structured_finetuned, global_sparsity_structured_finetuned, sparsity_details_structured_finetuned)\n",
    "\n",
    "# Unstructured Pruned + Scratch Model\n",
    "flops_unstructured_scratch = compute_flops(scratch_unstructured)\n",
    "global_sparsity_unstructured_scratch, sparsity_details_unstructured_scratch = analyze_sparsity(scratch_unstructured)\n",
    "print_analysis(\"Unstructured Pruned Model (50%) + Scratch\", flops_unstructured_scratch, global_sparsity_unstructured_scratch, sparsity_details_unstructured_scratch)\n",
    "\n",
    "# Structured Pruned + Scratch Model\n",
    "flops_structured_scratch = compute_flops(scratch_structured)\n",
    "global_sparsity_structured_scratch, sparsity_details_structured_scratch = analyze_sparsity(scratch_structured)\n",
    "print_analysis(\"Structured Pruned Model (50%) + Scratch\", flops_structured_scratch, global_sparsity_structured_scratch, sparsity_details_structured_scratch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLtrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

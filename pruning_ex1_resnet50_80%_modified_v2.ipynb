{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning 실험\n",
    "\n",
    "### \"RETHINKING OF THE VALUE OF THE NETWORK PRUNING\" 논문을 implemenatation 한 것. \n",
    "\n",
    "본 과정은 ChatGPT 와 함께 진행하였으며 Pruning 에 대한 전반적인 이해도를 높이고 실제 경량화와 성능 차이를 확인하기 위해서 진행하였습니다. \n",
    "\n",
    "Baseline model : ResNet-50\n",
    "\n",
    "Training dataset : CIFAR100 \n",
    "\n",
    "Pruning setup : 80%\n",
    "\n",
    "Pruning strategy : filter pruning vs Unstructure Pruning \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 : Dataset 로드 & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR100 데이터를 위한 Preprocess\n",
    "# 여러 이미지 transformation을 하나의 pipeline으로 통합 \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224), #ResNet에 맞기 위해 224 로 중앙 crop \n",
    "    transforms.ToTensor(), #Image 를 pytorch tensor 형태로 변형 \n",
    "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training set size: 50000 samples\n",
      "Test set size: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "# # CIFAR-100 Dataset 로드 \n",
    "\n",
    "# Automatically download CIFAR-100 and load it into the training and test datasets\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)  # Automatically download and load training data\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)  # Automatically download and load test data\n",
    "\n",
    "# Create DataLoaders for the CIFAR-100 train and test datasets\n",
    "# DataLoader는 모델이 여러 샘플을 동시에 처리할 수 있게 함. \n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "\n",
    "# Check dataset sizes to ensure they are loaded correctly\n",
    "print(f\"Training set size: {len(train_dataset)} samples\")\n",
    "print(f\"Test set size: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: ResNet 모델 초기화 (ImageNEt으로 사전 훈련된 가중치를 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning 사용. \n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STep4 : ResNet-50 모델의 마지막 Layer, FC layer을 CIFAR100에 맞춰 조정 \n",
    "\n",
    "이는 기존의 ImageNet을 위한 ResNet-50 모델은 1000개 클래스를 분류하는 모델이므로 조정해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if hasattr(model, 'fc'):  # Check if the model has an 'fc' attribute (final fully connected layer)\n",
    "    num_ftrs = model.fc.in_features  # Get the number of input features for the final layer\n",
    "    model.fc = nn.Linear(num_ftrs, 100)  # Replace it with 100 output neurons for CIFAR-100\n",
    "else:\n",
    "    raise AttributeError(\"The model doesn't have an 'fc' attribute. Make sure you are using a ResNet model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : model 을 GPU에 옮기기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: 손실함수와 최적화 함수 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # 다중 분류를 위한 크로스 엔트로피 손실함수 \n",
    "# label_smoothing 을 사용하여 \n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr = 0.001,\n",
    "                      momentum= 0.9,\n",
    "                      weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label smoothing 이란 ? \n",
    "    분류 모델 학습 시 사용되는 정규화 기법. 과확신을 방지하기 위해 사용 .\n",
    "    one-hot encoding 시 정답을 1, 그 외를 0으로 설정하지만 smoothing 을 통해 soft label을 만듦. \n",
    "    [1, 0, 0, 0, .... 0] => [0.9, 0.001, 0.001 ... 0.001]\n",
    "\n",
    "    (출처 : https://maxima-lab.tistory.com/entry/Deep-Learning-Label-Smoothing-Tensorflow )     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Validation loss를 계산하기 위한 validation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, test_loader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient computation during evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU if available\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    return val_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : 훈련 Loop 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "#Early Stopping 설정\n",
    "early_stopping_patience = 8\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs = 50):\n",
    "    global best_val_loss, epochs_no_improve\n",
    "\n",
    "    for epoch in range (num_epochs):\n",
    "        running_loss = 0.0 #훈련 중 loss 를 추적 \n",
    "        model.train() #훈련 모델 설정   \n",
    "\n",
    "        #tqdm 을 활용하여 각 epoch 마다 progress bar 표시 \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) #Data를 GPU로 옮기기 \n",
    "            optimizer.zero_grad() #각 batch 에서 나온 grad를 초기화. \n",
    "            outputs = model(inputs) # Forward Pass\n",
    "            loss = criterion(outputs, labels) #loss를 계산 \n",
    "            loss.backward() #backpropagation, gradient 계산\n",
    "            optimizer.step() #모델의 가중치 업데이트\n",
    "            running_loss += loss.item() # loss를 누적 \n",
    "\n",
    "            # progress bar 표시\n",
    "            progress_bar.set_postfix(loss = running_loss / len(train_loader))\n",
    "        \n",
    "        val_loss = validate_model(model, test_loader, criterion)\n",
    "        print(f\"Epoch [{epoch+1} / {num_epochs}], Loss : {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        #validation loss가 개선되었는지 확인\n",
    "        if val_loss < best_val_loss :\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else :\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        \n",
    "        # Early stopping check\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : 모델을 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Original and Pruned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./original_resnet50.pth\")\n",
    "# After pruning (in the next step), we will save the pruned model too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuilding the Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_pruned_model(pruned_model):\n",
    "    # Create a new ResNet-50 model instance\n",
    "    new_model = models.resnet50()\n",
    "    new_model.fc = nn.Linear(2048, 100)  # Adjust the output layer for CIFAR-100\n",
    "    new_model.load_state_dict(pruned_model.state_dict(), strict=False)  # Load pruned weights\n",
    "    return new_model\n",
    "\n",
    "# Rebuild the pruned model\n",
    "reconstructed_model = rebuild_pruned_model(model)\n",
    "# Save the reconstructed model\n",
    "torch.save(reconstructed_model.state_dict(), \"./reconstructed_resnet50.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing FLOPs and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "        Original Model  Pruned Model  Reconstructed Model\n",
      "FLOPs     4.131899e+09  4.131899e+09         4.131899e+09\n",
      "Params    2.371293e+07  2.371293e+07         2.371293e+07\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "# Function to compute FLOPs and parameters\n",
    "def compute_metrics(model, input_size=(3, 224, 224)):\n",
    "    input_data = torch.randn(1, *input_size).to(next(model.parameters()).device)\n",
    "    flops, params = profile(model, inputs=(input_data,))\n",
    "    return flops, params\n",
    "\n",
    "# Compare FLOPs and parameters for original, pruned, and reconstructed models\n",
    "original_flops, original_params = compute_metrics(model)\n",
    "pruned_flops, pruned_params = compute_metrics(model)\n",
    "reconstructed_flops, reconstructed_params = compute_metrics(reconstructed_model)\n",
    "\n",
    "# Display comparison\n",
    "comparison = {\n",
    "    \"Original Model\": {\"FLOPs\": original_flops, \"Params\": original_params},\n",
    "    \"Pruned Model\": {\"FLOPs\": pruned_flops, \"Params\": pruned_params},\n",
    "    \"Reconstructed Model\": {\"FLOPs\": reconstructed_flops, \"Params\": reconstructed_params}\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "import pandas as pd\n",
    "comparison_df = pd.DataFrame(comparison)\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 782/782 [01:56<00:00,  6.70it/s, loss=2.79] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 50], Loss : 2.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 782/782 [01:55<00:00,  6.77it/s, loss=1.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2 / 50], Loss : 1.5916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 782/782 [01:56<00:00,  6.71it/s, loss=1.36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3 / 50], Loss : 1.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 782/782 [01:53<00:00,  6.87it/s, loss=1.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4 / 50], Loss : 1.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 782/782 [01:52<00:00,  6.95it/s, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 50], Loss : 1.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 782/782 [01:52<00:00,  6.92it/s, loss=1.02] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6 / 50], Loss : 1.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 782/782 [01:53<00:00,  6.90it/s, loss=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7 / 50], Loss : 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 782/782 [01:53<00:00,  6.89it/s, loss=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8 / 50], Loss : 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 782/782 [01:55<00:00,  6.76it/s, loss=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9 / 50], Loss : 0.8931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 782/782 [01:53<00:00,  6.87it/s, loss=0.872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10 / 50], Loss : 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 782/782 [01:53<00:00,  6.91it/s, loss=0.859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11 / 50], Loss : 0.8591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 782/782 [01:52<00:00,  6.95it/s, loss=0.849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12 / 50], Loss : 0.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 782/782 [01:49<00:00,  7.13it/s, loss=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13 / 50], Loss : 0.8429\n",
      "Early stopping triggered after 13 epochs.\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=50)\n",
    "\n",
    "# Save the original model\n",
    "torch.save(model.state_dict(), './original_resnet50.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : 모델 평가 \n",
    "accuracy 뿐만 아니라 f1 score, precision, recall, inference_time 도 함께 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Evaluation:\n",
      "Accuracy: 81.38%\n",
      "Precision: 0.8156, Recall: 0.8138, F1-Score: 0.8136\n",
      "Inference Time: 7.8881 seconds\n",
      "Model Size: 95.18 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    start_time = time.time()  # Start timer for inference time\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Accuracy calculation\n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    # Precision, Recall, F1-score\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Inference time\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    return accuracy, precision, recall, f1, inference_time\n",
    "\n",
    "# Function to calculate model size\n",
    "def calculate_model_size(model):\n",
    "    torch.save(model.state_dict(), \"temp_model.pth\")\n",
    "    model_size = os.path.getsize(\"temp_model.pth\") / 1e6  # Convert to MB\n",
    "    os.remove(\"temp_model.pth\")\n",
    "    return model_size\n",
    "\n",
    "# Step 2: Evaluate the original trained ResNet-50 model\n",
    "print(\"Original Model Evaluation:\")\n",
    "accuracy, precision, recall, f1, inference_time = evaluate_model(trained_model, test_loader)\n",
    "model_size = calculate_model_size(trained_model)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "print(f\"Model Size: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11 : Pruning \n",
    "1. Unstructured Pruning (80%) no Fine-tuning vs with fine-tuning\n",
    "2. Structured Pruning (80% filter) no FIne-tuning vs with fine-tuning\n",
    "3. Unstructured Pruning (80%) with scratch\n",
    "4. Strcuctured Pruning with scratch \n",
    "\n",
    "위와 같은 6개의 pruning 모델 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured Pruning (individual weight를 가지치기)\n",
    "def apply_unstructured_pruning(model, amount=0.8):\n",
    "    # Conv2d 와 Linear layer에 pruning 적용\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            print(f'Applied unstructured pruning to {name}, amount={amount}')\n",
    "    return model\n",
    "\n",
    "# Structured Pruing (filter pruning)\n",
    "def apply_structured_pruning(model, amount=0.8):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            prune.ln_structured(module, name='weight', amount=amount, n=1, dim=0)  # dim=0 means prune filters\n",
    "            print(f'Applied structured pruning to {name}, amount={amount}')\n",
    "    return model\n",
    "\n",
    "#Fine-tuning 함수\n",
    "def fine_tune_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(train_loader))\n",
    "        val_loss = validate_model(model, test_loader, criterion)\n",
    "        print(f'Epoch {epoch+1}, Fine-tuned Training Loss: {running_loss/len(train_loader):.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "# Pruned model 의 가중치를 재 초기화하는 함수 \n",
    "def reinitialize_weights(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            nn.init.kaiming_normal_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "    return model\n",
    "\n",
    "# Function to train from scratch\n",
    "def train_scratch(model, train_loader, test_loader, criterion, optimizer, num_epochs=20):\n",
    "    return fine_tune_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12 : 가지치기 모델 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied unstructured pruning to conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to fc, amount=0.8\n",
      "Applied structured pruning to conv1, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer1.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to fc, amount=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 782/782 [01:49<00:00,  7.17it/s, loss=3.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 3.6185, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 782/782 [01:44<00:00,  7.46it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 3.5599, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 782/782 [01:45<00:00,  7.45it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 3.5597, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 782/782 [01:45<00:00,  7.39it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Fine-tuned Training Loss: 3.5598, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 782/782 [01:45<00:00,  7.44it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Fine-tuned Training Loss: 3.5601, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 782/782 [01:45<00:00,  7.45it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Fine-tuned Training Loss: 3.5600, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 782/782 [01:45<00:00,  7.41it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Fine-tuned Training Loss: 3.5599, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 782/782 [01:45<00:00,  7.44it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Fine-tuned Training Loss: 3.5596, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 782/782 [01:44<00:00,  7.45it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Fine-tuned Training Loss: 3.5599, Validation Loss: 3.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 782/782 [01:44<00:00,  7.46it/s, loss=3.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Fine-tuned Training Loss: 3.5599, Validation Loss: 3.6181\n",
      "Applied structured pruning to conv1, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer1.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv3, amount=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 782/782 [01:48<00:00,  7.18it/s, loss=4.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 4.6174, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 782/782 [01:44<00:00,  7.46it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 4.6264, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 782/782 [01:44<00:00,  7.45it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 4.6263, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 782/782 [01:44<00:00,  7.46it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Fine-tuned Training Loss: 4.6262, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 782/782 [01:44<00:00,  7.47it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Fine-tuned Training Loss: 4.6264, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 782/782 [01:44<00:00,  7.48it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Fine-tuned Training Loss: 4.6264, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 782/782 [01:44<00:00,  7.47it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Fine-tuned Training Loss: 4.6263, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 782/782 [01:44<00:00,  7.46it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Fine-tuned Training Loss: 4.6263, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 782/782 [01:47<00:00,  7.27it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Fine-tuned Training Loss: 4.6263, Validation Loss: 4.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 782/782 [01:49<00:00,  7.14it/s, loss=4.63] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Fine-tuned Training Loss: 4.6263, Validation Loss: 4.6257\n",
      "Applied unstructured pruning to conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer1.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer1.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer2.3.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.3.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.4.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer3.5.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.0.downsample.0, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.1.conv3, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv1, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv2, amount=0.8\n",
      "Applied unstructured pruning to layer4.2.conv3, amount=0.8\n",
      "Applied unstructured pruning to fc, amount=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 782/782 [01:54<00:00,  6.85it/s, loss=3.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 3.6190, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 782/782 [01:48<00:00,  7.24it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 3.5791, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 782/782 [01:50<00:00,  7.10it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 782/782 [01:49<00:00,  7.16it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 782/782 [01:51<00:00,  7.03it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Fine-tuned Training Loss: 3.5793, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 782/782 [01:47<00:00,  7.25it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 782/782 [01:48<00:00,  7.23it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 782/782 [01:50<00:00,  7.10it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Fine-tuned Training Loss: 3.5791, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 782/782 [01:51<00:00,  7.03it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Fine-tuned Training Loss: 3.5794, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 782/782 [01:51<00:00,  7.00it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Fine-tuned Training Loss: 3.5793, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 782/782 [01:47<00:00,  7.24it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Fine-tuned Training Loss: 3.5793, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 782/782 [01:50<00:00,  7.06it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 782/782 [01:52<00:00,  6.96it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Fine-tuned Training Loss: 3.5788, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 782/782 [01:50<00:00,  7.06it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Fine-tuned Training Loss: 3.5791, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 782/782 [01:50<00:00,  7.06it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Fine-tuned Training Loss: 3.5791, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 782/782 [01:51<00:00,  7.04it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Fine-tuned Training Loss: 3.5790, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 782/782 [01:51<00:00,  7.03it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 782/782 [01:51<00:00,  7.00it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 782/782 [01:50<00:00,  7.07it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Fine-tuned Training Loss: 3.5792, Validation Loss: 3.6367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 782/782 [01:50<00:00,  7.06it/s, loss=3.58] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Fine-tuned Training Loss: 3.5794, Validation Loss: 3.6367\n",
      "Applied structured pruning to conv1, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer1.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer1.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv1, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv2, amount=0.8\n",
      "Applied structured pruning to layer2.3.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.2.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.3.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.4.conv3, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv1, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv2, amount=0.8\n",
      "Applied structured pruning to layer3.5.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.0.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.0.downsample.0, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.1.conv3, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv1, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv2, amount=0.8\n",
      "Applied structured pruning to layer4.2.conv3, amount=0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 782/782 [01:54<00:00,  6.82it/s, loss=4.64] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Fine-tuned Training Loss: 4.6385, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 782/782 [01:49<00:00,  7.12it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 782/782 [01:50<00:00,  7.11it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 782/782 [01:50<00:00,  7.10it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Fine-tuned Training Loss: 4.6473, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 782/782 [01:49<00:00,  7.11it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 782/782 [01:50<00:00,  7.10it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 782/782 [01:50<00:00,  7.09it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 782/782 [01:49<00:00,  7.11it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 782/782 [01:49<00:00,  7.11it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Fine-tuned Training Loss: 4.6473, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 782/782 [01:50<00:00,  7.08it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 782/782 [01:50<00:00,  7.09it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 782/782 [01:50<00:00,  7.10it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 782/782 [01:50<00:00,  7.10it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 782/782 [01:50<00:00,  7.05it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 782/782 [01:49<00:00,  7.12it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Fine-tuned Training Loss: 4.6471, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 782/782 [01:50<00:00,  7.09it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 782/782 [01:49<00:00,  7.12it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 782/782 [01:50<00:00,  7.05it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 782/782 [01:50<00:00,  7.08it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 782/782 [01:50<00:00,  7.05it/s, loss=4.65] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Fine-tuned Training Loss: 4.6472, Validation Loss: 4.6459\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Step 1: Model 1 - Unstructured Pruning (80%) without Fine-Tuning\n",
    "model_unstructured = copy.deepcopy(trained_model)\n",
    "model_unstructured = apply_unstructured_pruning(model_unstructured, amount=0.8)\n",
    "\n",
    "# Step 2: Model 2 - Structured Pruning (80% Filter Pruning) without Fine-Tuning\n",
    "model_structured = copy.deepcopy(trained_model)\n",
    "model_structured = apply_structured_pruning(model_structured, amount=0.8)\n",
    "\n",
    "# Step 3: Model 3 - Unstructured Pruning (80%) with Fine-Tuning\n",
    "model_unstructured_finetuned = copy.deepcopy(trained_model)\n",
    "model_unstructured_finetuned = apply_unstructured_pruning(model_unstructured_finetuned, amount=0.8)\n",
    "fine_tuned_unstructured = fine_tune_model(model_unstructured_finetuned, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "# Step 4: Model 4 - Structured Pruning (80%) with Fine-Tuning\n",
    "model_structured_finetuned = copy.deepcopy(trained_model)\n",
    "model_structured_finetuned = apply_structured_pruning(model_structured_finetuned, amount=0.8)\n",
    "fine_tuned_structured = fine_tune_model(model_structured_finetuned, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "# Step 5: Model 5 - Unstructured Pruning (80%) + Scratch (Train from Scratch)\n",
    "model_unstructured_scratch = copy.deepcopy(trained_model)\n",
    "model_unstructured_scratch = apply_unstructured_pruning(model_unstructured_scratch, amount=0.8)\n",
    "model_unstructured_scratch = reinitialize_weights(model_unstructured_scratch)\n",
    "scratch_unstructured = train_scratch(model_unstructured_scratch, train_loader, test_loader, criterion, optimizer)\n",
    "\n",
    "# Step 6: Model 6 - Structured Pruning (80%) + Scratch (Train from Scratch)\n",
    "model_structured_scratch = copy.deepcopy(trained_model)\n",
    "model_structured_scratch = apply_structured_pruning(model_structured_scratch, amount=0.8)\n",
    "model_structured_scratch = reinitialize_weights(model_structured_scratch)\n",
    "scratch_structured = train_scratch(model_structured_scratch, train_loader, test_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13 : Pruned 모델 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 메서드 생성 \n",
    "def evaluate_and_print_results(models, model_names, test_loader):\n",
    "    for model, name in zip(models, model_names):\n",
    "        print(f\"\\n{name}:\")\n",
    "        accuracy, precision, recall, f1, inference_time = evaluate_model(model, test_loader)\n",
    "        model_size = calculate_model_size(model)\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "        print(f\"Inference Time: {inference_time:.4f} seconds, Model Size: {model_size:.2f} MB\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가지치기 된 모델이 얼마만큼 pruned 됐고, 얼마나 filter가 남았는지 확인하는 메서드 \n",
    "def print_pruned_percentage(model) : \n",
    "    for name, module in module.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                # unstructured pruning에서는 얼마나 많은 weights가 zero가 됐는지 확인\n",
    "                total_weights = module.weight_mask.numel()  # Total number of weights in the layer\n",
    "                pruned_weights = (module.weight_mask == 0).sum().item()  # Number of zeroed weights\n",
    "                pruned_percentage = 100 * pruned_weights / total_weights\n",
    "                print(f'Layer: {name} - Pruned {pruned_percentage:.2f}% of weights (Unstructured)')\n",
    "            elif hasattr(module, 'weight_orig'):\n",
    "                # Structured pruning: check how many filters/channels were pruned\n",
    "                total_filters = module.weight_orig.size(0)  # Number of filters (size in dim 0)\n",
    "                pruned_filters = (module.weight_orig.abs().sum(dim=[1, 2, 3]) == 0).sum().item()  # Zero filters\n",
    "                pruned_percentage = 100 * pruned_filters / total_filters\n",
    "                print(f'Layer: {name} - Pruned {pruned_percentage:.2f}% of filters (Structured)')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unstructured Pruning (80%):\n",
      "Accuracy: 2.11%\n",
      "Precision: 0.0138, Recall: 0.0211, F1-Score: 0.0035\n",
      "Inference Time: 8.3018 seconds, Model Size: 189.84 MB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Structured Pruning (80%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00%\n",
      "Precision: 0.0001, Recall: 0.0100, F1-Score: 0.0002\n",
      "Inference Time: 8.3174 seconds, Model Size: 189.02 MB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Unstructured Pruning + Fine-Tuning (80%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.51%\n",
      "Precision: 0.5310, Recall: 0.4751, F1-Score: 0.4733\n",
      "Inference Time: 8.3273 seconds, Model Size: 189.84 MB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Structured Pruning + Fine-Tuning (80%):\n",
      "Accuracy: 1.19%\n",
      "Precision: 0.0075, Recall: 0.0119, F1-Score: 0.0020\n",
      "Inference Time: 8.3616 seconds, Model Size: 189.02 MB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Unstructured Pruning + Scratch (80%):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.28%\n",
      "Precision: 0.5293, Recall: 0.4728, F1-Score: 0.4706\n",
      "Inference Time: 8.3304 seconds, Model Size: 189.84 MB\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Structured Pruning + Scratch (80%):\n",
      "Accuracy: 0.91%\n",
      "Precision: 0.0009, Recall: 0.0091, F1-Score: 0.0015\n",
      "Inference Time: 8.4074 seconds, Model Size: 189.02 MB\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/park/anaconda3/envs/NLtrans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 6가지 모델 비교\n",
    "models_to_compare = [\n",
    "    model_unstructured, model_structured, fine_tuned_unstructured, \n",
    "    fine_tuned_structured, scratch_unstructured, scratch_structured\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"Unstructured Pruning (80%)\", \"Structured Pruning (80%)\", \n",
    "    \"Unstructured Pruning + Fine-Tuning (80%)\", \"Structured Pruning + Fine-Tuning (80%)\", \n",
    "    \"Unstructured Pruning + Scratch (80%)\", \"Structured Pruning + Scratch (80%)\"\n",
    "]\n",
    "\n",
    "evaluate_and_print_results(models_to_compare, model_names, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d5d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display model parameters\n",
    "def print_model_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {total_params}\")\n",
    "    return total_params\n",
    "\n",
    "# Call the function after each pruning step to check parameters\n",
    "for model in models_to_compare:\n",
    "    print_model_parameters(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete original models after pruning to free memory\n",
    "del model_unstructured\n",
    "del model_structured\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLtrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
